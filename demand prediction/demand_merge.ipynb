{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging  cleaned201706.csv\n",
      "merging  cleaned201707.csv\n",
      "merging  cleaned201708.csv\n",
      "training data merge complete\n"
     ]
    }
   ],
   "source": [
    "#This script merges cleaned citi bike trip data from each month together, and count the number\n",
    "#of trips departing each station at a specific day and time bucket, and fill those time buckets \n",
    "#with 0 trips. \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#This function reads cleaned data and merge them according to timebins\n",
    "#so we can perform regression on number of trips. \n",
    "def read_cleaned(filename):\n",
    "    global name\n",
    "    raw = pd.read_csv(filename,usecols=[2,3,4,5,6,7,10,11])\n",
    "    return raw\n",
    "\n",
    "\n",
    "#This function computes the Cartesian product between two dataframes.\n",
    "#This is taken from https://mkonrad.net/2016/04/16/cross-join--cartesian-product-between-pandas-dataframes.html\n",
    "def df_crossjoin(df1, df2):\n",
    " \n",
    "    df1['_tmpkey'] = 1\n",
    "    df2['_tmpkey'] = 1\n",
    "\n",
    "    product = pd.merge(df1, df2, on='_tmpkey').drop('_tmpkey', axis=1)\n",
    "\n",
    "    df1.drop('_tmpkey', axis=1, inplace=True)\n",
    "    df2.drop('_tmpkey', axis=1, inplace=True)\n",
    "    return product\n",
    "\n",
    "#This function reads in monthly rides and merges them into time buckets, and returns the counts.\n",
    "#Moreover, it fills in the missing observations where 0 number of rides were observed. \n",
    "def merge_month(to_add):\n",
    "    raw = to_add\n",
    "    #merge trips into time buckets on a given day.\n",
    "    drop_end_station = raw.drop(columns=['End_Station_Latitude', 'End_Station_Longitude'])\n",
    "    incomplete = drop_end_station.groupby(drop_end_station.columns.tolist(),as_index=False).size().reset_index().rename(columns={0:'Count'})\n",
    "\n",
    "    #produce a dataframe with 0 counts for all locations, all times, and all dates\n",
    "    #then, insert rows into the incomplete merged dataframe if those rows are missing, i.e.\n",
    "    #the number of trips is 0 for that particular combination.\n",
    "    location = raw[['Start_Station_Name','Start_Station_Latitude','Start_Station_Longitude']]\n",
    "    location = location.drop_duplicates()\n",
    "    date_info = raw[['Holiday','Date']]\n",
    "    date_info = date_info.drop_duplicates()\n",
    "    time_bucket = raw['Start_Time']\n",
    "    time_bucket = pd.DataFrame(time_bucket.drop_duplicates())\n",
    "    #cross product of the three locations. \n",
    "    cruz = df_crossjoin(time_bucket,location)\n",
    "    empty_cross = df_crossjoin(cruz,date_info)\n",
    "    empty_cross['Count']= 0 \n",
    "    \n",
    "    #combine the empty list with actual observations, then merge using groupby.\n",
    "    c = pd.concat([empty_cross,incomplete])\n",
    "    merge_index = ['Start_Time','Start_Station_Name','Start_Station_Latitude','Start_Station_Longitude','Holiday','Date']\n",
    "    complete_month = c.groupby(merge_index).sum()\n",
    "    complete_month = complete_month.reset_index()\n",
    "    return complete_month\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    name = ['Start_Time','Start_Station_Name','Start_Station_Latitude','Start_Station_Longitude','End_Station_Latitude','End_Station_Longitude','Holiday','Date']\n",
    "    \n",
    "    database_name = ['Start_Time','Start_Station_Name','Start_Station_Latitude','Start_Station_Longitude','Holiday','Date','Count']\n",
    "   \n",
    "    training_date = ['201706','201707','201708']\n",
    "    training_database = pd.DataFrame(columns=database_name)\n",
    "    \n",
    "    \n",
    "    #create training database\n",
    "    for i in range(len(training_date)):\n",
    "        \n",
    "        filename = 'cleaned'+training_date[i]+'.csv'\n",
    "        print('merging ',filename)\n",
    "        \n",
    "        to_add = read_cleaned(filename)\n",
    "        \n",
    "        #merge the rides in each month\n",
    "        merged_month_rides = merge_month(to_add)\n",
    "        training_database = pd.concat([training_database,merged_month_rides])\n",
    "        \n",
    "        \n",
    "    training_database.to_csv('demand_merged_data.csv',index=False)\n",
    "    print('training data merge complete')  \n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
