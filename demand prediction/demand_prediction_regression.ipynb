{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376328\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/demandDNN23', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022303D69630>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/demandDNN23\\model.ckpt-7861\n",
      "INFO:tensorflow:Saving checkpoints for 7862 into /tmp/demandDNN23\\model.ckpt.\n",
      "INFO:tensorflow:loss = 157924.0, step = 7862\n",
      "INFO:tensorflow:Saving checkpoints for 7871 into /tmp/demandDNN23\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 157466.0.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-04-17:32:10\n",
      "INFO:tensorflow:Restoring parameters from /tmp/demandDNN23\\model.ckpt-7871\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-04-17:32:12\n",
      "INFO:tensorflow:Saving dict for global step 7871: average_loss = 0.163758, global_step = 7871, loss = 44716.7\n",
      "INFO:tensorflow:Restoring parameters from /tmp/demandDNN23\\model.ckpt-7871\n",
      "         Actual_Count  Predicted_Count\n",
      "230581            0.1         0.212352\n",
      "578844            0.0         0.053212\n",
      "1081235           0.2         0.716430\n",
      "75782             0.0         0.002497\n",
      "330124            0.5         0.360799\n",
      "270843            0.0         0.070330\n",
      "1242142           0.0         0.290760\n",
      "1200146           0.7         0.927945\n",
      "505775            0.0         0.046044\n",
      "1309058           0.0         0.135553\n",
      "1284754           0.4         0.264993\n",
      "840256            0.3         0.217588\n",
      "590325            0.3         0.146983\n",
      "816203            0.3         0.230470\n",
      "1340117           0.5         0.158354\n",
      "729531            0.0         0.338437\n",
      "876196            0.4         0.366831\n",
      "1258623           2.0         1.011075\n",
      "694837            0.0         0.134853\n",
      "604239            0.1         0.353297\n",
      "1334271           0.0         0.085486\n",
      "6951              0.5         0.148055\n",
      "1097140           0.0         0.361957\n",
      "56585             0.0         0.001793\n",
      "396335            0.2         0.103352\n",
      "823237            0.7         0.438832\n",
      "972662            0.1         0.029381\n",
      "368263            0.0         0.571111\n",
      "1282637           0.3         0.373353\n",
      "233569            0.2         0.248736\n",
      "...               ...              ...\n",
      "95531             0.0         0.211135\n",
      "103637            0.1         0.031815\n",
      "48257             0.0         0.031593\n",
      "145817            0.6         0.252708\n",
      "811275            1.4         1.192160\n",
      "916084            0.1         0.042092\n",
      "270818            0.1         0.136901\n",
      "954863            0.0        -0.006535\n",
      "8374              0.0         0.129223\n",
      "378538            0.0         0.939179\n",
      "270948            0.1         0.244315\n",
      "775855            0.5         0.671437\n",
      "1166909           2.1         0.799716\n",
      "1321279           0.3         0.216955\n",
      "709652            2.2         0.740330\n",
      "905342            0.1         0.063334\n",
      "189777            0.0         0.258293\n",
      "630122            0.1         0.558690\n",
      "409495            0.1         0.314730\n",
      "1223806           0.6         0.703643\n",
      "1296117           2.4         1.147302\n",
      "882034            0.3         0.139445\n",
      "300945            2.8         1.156200\n",
      "424621            0.1         0.076617\n",
      "848415            0.6         0.448732\n",
      "598448            0.0         0.089406\n",
      "460577            0.1         0.070556\n",
      "141977            0.6         0.302729\n",
      "520391            0.0         0.034139\n",
      "605764            0.1         0.201347\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#This script reads in cleaned and merged data and performs regressions to predict number of bikes\n",
    "#departing a bike station given the following parameters:\n",
    "#Time bucket, station latitude and longitude, hourly temperature, precipitation, and whether the day is a holiday/weekend or not. \n",
    "#Training takes about 12 hours on my Surface Pro 4.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "#generate tensorflow input function for gradient descent. \n",
    "def get_input_fn(data_set, num_epochs, shuffle):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "      x = pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "      y = pd.Series(data_set[LABEL].values),\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=data_set.shape[0])\n",
    "     \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    COLUMNS = ['Start_Time','Start_Station_Latitude','Start_Station_Longitude','Count','Precipitation','Temperature']\n",
    "    FEATURES = ['Start_Time','Start_Station_Latitude','Start_Station_Longitude','Precipitation','Temperature']\n",
    "    LABEL = 'Count'   \n",
    "                                      \n",
    "    #read data                             \n",
    "    data = pd.read_csv('demand_prediction_data.csv')\n",
    "   \n",
    "    #normalize feature and label vectors\n",
    "    for k in FEATURES:\n",
    "        data[k] = (data[k] - data[k].mean()) / (data[k].max() - data[k].min())\n",
    "    data['Count'] = data['Count']/10    \n",
    "    \n",
    "    #randomly split data set into 70% training set, 20% validation set, and 10% test set.\n",
    "    length = len(data['Count'])\n",
    "    print(length)\n",
    "    selection = np.random.rand(length)\n",
    "    training = (selection < 0.7)\n",
    "    training_set = data[training]\n",
    "    valid_test = data[~training]\n",
    "    \n",
    "    length = len(valid_test['Count'])\n",
    "    selection = np.random.rand(length)\n",
    "    valid = (selection < 0.66)\n",
    "    validation_set = valid_test[valid]\n",
    "    test_set = valid_test[~valid]\n",
    "    \n",
    "    #define feature columns \n",
    "    feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "    \n",
    "    #Evaluate on validation set every 10 epochs, and train for 10000 epochs. \n",
    "    for i in range(1000):\n",
    "        \n",
    "        #Implement regression on Tensorflow.\n",
    "        #regressor = tf.estimator.LinearRegressor(feature_columns=feature_cols,\n",
    "        regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols, hidden_units=[64,32,64],                     \n",
    "                          #optimizer=tf.train.FtrlOptimizer(\n",
    "                          #learning_rate=0.1,\n",
    "                          #l1_regularization_strength=10,\n",
    "                          #l2_regularization_strength=10))\n",
    "                          optimizer=tf.train.AdamOptimizer(\n",
    "                          learning_rate=0.001,\n",
    "                          beta1=0.9,\n",
    "                          beta2=0.999,  \n",
    "                          #epsilon=1e-5),model_dir=\"/tmp/demandLinear1\")\n",
    "                          epsilon=1e-8),model_dir=\"/tmp/demandDNN23\")\n",
    "        \n",
    "        regressor.train(input_fn=get_input_fn(training_set,num_epochs=10, shuffle=True), steps=10)\n",
    "        \n",
    "        ev = regressor.evaluate(\n",
    "        input_fn=get_input_fn(validation_set, num_epochs=1, shuffle=False))\n",
    "        \n",
    "    #To generate examples of predictions, randomly select 100 rows from the test set. \n",
    "    snip = test_set.sample(100)\n",
    "    pred = regressor.predict(\n",
    "    input_fn=get_input_fn(snip, num_epochs=1, shuffle=False))\n",
    "    predictions = list(p[\"predictions\"] for p in itertools.islice(pred, 100))\n",
    "    pre = [float(element) for element in predictions]\n",
    "    comparison = pd.DataFrame()\n",
    "    comparison['Actual_Count']=snip['Count'] \n",
    "    comparison['Predicted_Count']=pre\n",
    "    print(comparison.sample(frac=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
